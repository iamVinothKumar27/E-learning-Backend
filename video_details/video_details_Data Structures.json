[
    {
        "video_id": "zWg7U0OEAoE",
        "title": "Lecture - 1 Introduction to Data Structures and Algorithms",
        "url": "https://www.youtube.com/watch?v=zWg7U0OEAoE",
        "duration": 3211,
        "transcript": "Welcome \nto data structures and algorithms. We are going to learn today some basic terminology\nregarding data structures and the notations that you would be following in the rest of\nthis course. We will begin with some very simple definitions. An algorithm which is\nan outline of the steps that a program has to take or any computational procedure has\nto take. A program on the other hand is an implementation of an algorithm and it could\nbe in any programming language. Data structure is the way we need to organize the data, so\nthat it can be used effectively by the program. So you are all familiar with certain data\nstructures, an array or a list for instance. In this course you will be seeing a lot more\ndata structures in this course and you will see how to use them in various algorithms.\nWe will take a particular problem, try to solve that problem and in the process develop\ndata structures, the best way of organizing the data, associated with that problem. What\nis an algorithmic problem? An algorithmic problem is essentially, that you have a certain\nspecifications of an input as is given here and you specify what the output should be\nlike. And a specification of an input could be, here is one specification, a sorted, non\ndecreasing sequence of natural numbers of non-zero, finite length. That's an input,\nthat's a completely specified input. I have given 2 examples here of inputs which meet\nthe specification and I have not given any output specification yet here. Now what is an instance? These are 2 instances\nof the input. This is the specification for the input and you can have any possible instance,\nyou can take any sequence of sorted, non-decreasing numbers and that would form an input instance.\nSo there are many input instances possible here. An algorithm is essentially, describing the\nactions that one should take on the input instance to get the output as desired, as\nis specified. And again there can be infinitely many input instances and there can be infinitely\nmany algorithms for solving certain problem. Each one of you could do it in a slightly\ndifferent way. That brings the notion of good algorithm.\nIf there are so many different algorithms for solving a certain problem, what is a good\nalgorithm? Good algorithm for us is an efficient algorithm. Anything that is efficient is good.\nWhat is efficient? Efficient is something, which has small running time and takes less\nmemory. These will be the two measures of efficiency that we will be working with. There\ncould also be other measures of efficiency. But these are the only two things we would\nbe considering in this course. And most of our time we would be spending with the running\ntime really. Space, of course we will be analyzing the space and most of the time would be spent\nin worrying about the running time of an algorithm. And we would be interested in the efficiency\nof algorithms, as a function of the input size. So clearly you can imagine that, if I have\na small input and my algorithm running on that input or my program running on that input\nwill take less amount of time. If the input becomes 10 times larger, then the time taken\nby the program would also grow. It may it becomes 10 times, may be it becomes 20 times\nor may be it becomes 100 times, I do not know. It is this behavior of the increase in the\nrunning time, with the increase in the size of input that would also be of our interest\nto us. We will come to all of these in a short while as we go through these slides. How does one measure running time? So I said\nefficiency, running time, very important. How does one measure the running time of an\nalgorithm? One way would be, I have put down here as an experimental study. You have a\ncertain algorithm and you have to implement that algorithm, which means you have to write\na program in a certain programming language. You run the program with varying data sets,\nsome smaller, some larger data sets, some would be of some kinds and some would be of\ndifferent kinds, so varying composition. And then you clock the time that the program takes\nand clock does not mean that you should sit down near stopwatch. Perhaps you can use the\nsystem utility like let's say System. Current Time Millis (), to clock the time that the\nprogram takes and then from that you try and figure out, how good your algorithms is, so\nthat is what one would call an experimental study of the algorithm. This has certain limitations. So I put them\ndown. First you have to implement the algorithm to be able to determine how good your algorithm\nis you have to Implement it and that is already a huge overhead, considerable amount of time\nhas to be spent in doing this. When your experiments can be done only on a limited set of inputs.\nAfter all I said the number of instances is infinitely large and you can run your experiment\nonly on a small set of instances and that might not be really indicative of the time\nthat your algorithm is taking for other inputs, which you have not considered in your experiment. Further if you have two algorithms and you\nhave to decide, which one is better you have to use exactly the same platforms to do the\ncomparison. Platform I mean both the hardware and software environment. Because as you can\nimagine, different machines would make a difference, not just different machines in fact even the\nusers who are working on that system at that particular point would make a difference on\nthe running time of an algorithm. It becomes very messy, if you have to do it this way. What we are going to do in the part of this\ncourse, in fact in this very first lecture is to develop the general methodology, which\nwill help us to analyze running time of algorithms. We are going to do it as follows: we are going\nto first develop a high level description of an algorithm, a way of describing an algorithm\nand we are going to use this description to figure out the running time and not to implement\nit to any system. A methodology would help us take into account\nof all possible input instances and it would help us and also it will allow us to evaluate\nthe efficiency of the algorithm in a way that it is independent of the environment, independent\nof the platform that we are using. I said we will give the high level description\nof the algorithm. This very first point here, we will give a high level description. So,\nwhat is this? So this brings me to what? We will call this Pseudo-code. And this is how we are going to be specifying\nall our algorithms for the purposes of this course. Here is an example of pseudo code and you\nmight have seen this in your earlier courses also. What is this algorithm doing? This algorithm\ntakes an array A, which stores an integer in it and it is trying to find the maximum\nelement in this array. What I have written here is not a program because I think the\nsyntax is all wrong. But it is pseudo-code; it is a mixture of natural language and some\nhigh-level programming concepts. I am going to use a for loop, do loop, I am\ngoing to use if-then-else statement and I am going to use a while loop. But I will not\nbother about whether there should be a semicolon here or there should be colon here and I am\nnot going to bother about those are things are required by the compiler but for our understanding\nthis is completely clear what this program is doing. So what it is doing? It is keeping\ntrack of the maximum variable in a variable called current max which is initialized to\nthe first element of the array. And Then it is going to run through the remaining element\nof the array, compare them with the current maximum element. Current Max ← A [0]. If\nthe current maximum element is less than the current element, then it would update the\ncurrent max. A[i] becomes the new max and then when the loop terminates we would just\nreturn current max. If current Max < A[i] then current Max ← A[i]\nreturn current Max It is a very simple algorithm but just with\nthis pseudo-code, you are able to understand what it is doing. This will not run on any\ncomputer since it is the pseudo-code, but it conveys the idea or the concepts any question\nup to this point? That is what I saying most structured pseudo code, most structured than\nusual course but it is less for than formal programming. And How pseudo-code will look like? We will\nuse standard numeric and Boolean expressions in it. Instead of the assignment operator which is\n'=' in java, I will use ← and instead of the equality operator, an equality relationship\nin java which is '= =' the same in C, I will just use '='. I will declare methods with\nthe algorithmic name and the parameter it takes. Algorithm name (param 1, param2) I will use all kinds of programming construct\nlike if ...then statement, if ...then... [else] statement, while ... do, repeat ...until,\nfor ... do and to index array I will say A[i], A [i, j]. It should be clear in what it is\ndoing. I will use return when the procedure terminates\nand return value will tell, what the value returned by the particular procedure or a\nfunction. When I have to make a call to a method, I will specify that with the name\nof the method and the argument and what is the object that is used. Any question to this\npoint. What was the object? This is specifies the type of the value returned\nby the particular method. You will see more of this, when we come across more pseudo-code.\nHow do we analyze algorithms? First we identify what are the primitive operations in our pseudo-code.\nWhat is a primitive operation? It is a low level operation. Example is a data movement\nin ,I do an assignment from one to another, I do a control statement which is a branch\n(if... then ...else) subroutine call or return. I do arithmetic operations or logical operations\nthese are all we called as a primitive operation. • Data movement (assign)\n• Control (branch, subroutine call, return) • Arithmetic an logical operations (e.g.\naddition, comparison) In my pseudo code, I just inspect the pseudo\ncode and count the number of primitive operations that are executed by an algorithm. Let us\nsee an example of sorting. You all know what sorting is, the input is some sequence of\nnumbers and output is a permutation of the sequence which is in non decreasing order.\nWhat are  the requirements for the output? It should\nbe in non-decreasing order and it should be the permutation of the input. Any set of numbers which are in non-decreasing\norder does not make an output. Algorithm should sort the numbers that were given to it and\nnot just produce the sequence of numbers as an increasing order. Clearly the running time\nwill depends upon, number of elements (n) and often it depends upon, how sorted these\nnumbers are. If they are already in sorted order then the algorithm will not take a long\ntime. It also depends upon the particular algorithm we use. The running time would depend\nupon all these things. The first sorting technique we use is the one that you have used very\noften. Let us say when you are playing game of cards. What is the strategy you follow, when you\nare picking up a set of cards that have been dealt out to you? You like to keep them in\na sorted order in your hand. You start with the empty hand and you pick up the first card,\nthen you take the next card and insert it at the appropriate place. Suppose if I have some five cards in your\nhand already, let us say 2, 7, 9, jack and queen. Then I getting 8, so I am going to\nput it between 7 and 9. That is the right place it has to be placed in. I am inserting\nit at the appropriate place and that is why this technique is called insertion sort. I\nkeep on doing this, till I have picked up all the cards and inserted in the appropriate\nplace. So this is the pseudo-code for insertion sort.\nI will give an array of integers A contain input and output is a permutation of the original\nnumbers, such that it is sorted. The output is also going to be in the same array.\nA [1]≤ A [2]≤ _ ≤ A[n] This is the input, output specification. I\nam going to have 2 variables or indices i and j. The array is going to be sorted from\na [1] through a [j-1]. The jth Location is an element which I have to insert appropriately\nto the right place Clearly j has to vary from 2 to n. For j ←2 to n I am going to look at jth element and I put\nthat in key. Key ←A[j] I have to insert A [j] or the key in to the sorted sequence\nwhich is A [1] through A [j-1]. i.e. A [1_j-1] I am going to use the index i to do this.\nWhat is index i going to do? Index i is going to run down from j-1 down to 1. We going to\ndecrease index i, which is what we are doing in here in this while do loop. It starts with the value j-1.And what I am\ngoing to do? I have to insert 7 and I am going to move 9 to 7th location, because 9 is more\nthan 7. Then I compare 7 with 8 and 8 is still greater than 7, so I will move it right. Then\nI compare 7 with 6. As 6 is smaller than 7,Now I found the right place for 7, I would put\n7 here ,that exactly what is happening here. I run through this loop, till I find an element\nwhich is less than key. Key is the element which I am trying to insert. This loop will\ncontinue while the element, I am consider is more than key and this loop will terminate,\nwhen I see an element which is less than key or the loop will terminate when I reach i=0.\nWhile i >0 and A[i] > key do A [i+1] ← A[i] That means I have moved everything to the\nright and I should insert the element at the very first place and what am I doing Here?\nI am just shifting the element one step to the right. Do A [i+1] ← A[i] Note that I have to insert 7 at the right\nplace, so I shift 9 right to 1 step. 9th location becomes empty, then I shift 8 to 1 step, so\nthis 8th location becomes empty and now I can put 7 here. i + 1 is the index, which\nwould be the empty location eventually and i put the key there. A [i+1]← key All of\nyou can implement it. May be you would have implemented it in a slightly different way,\nthat would give you a different program, but the algorithm is essentially the same. You\nare going to find the right place for the element and insert it.Now Let us analyze this\nalgorithm. I have put down the algorithm on the left\n(There is a small mistake here there should be a left arrow Please make a correction on\nthat) .What we are going to do? A [i+1] ← A key\nLet us count. Key ← A[j]\nI ← j-1 These are all my primitive operations. Here\nI have to do primitive operations, why because I am comparing i with 0 and I am comparing\nA[i] with key, I am also taking and, so there are three primitive operations.\nwhile i >0 and A[i] > key Each of the operation takes a certain amount\nof time, depending upon the computer system you have.C1,C2,C3,C4,C5,C6 just Reflect or\njust represent the amount of time taken for these operations and they can be in any units.\nAnd here I am counting the number of times, each of these operations is executed is done\nin this entire program. Why this operation is done n times? I start\nby assigning j =2 then assign 3, 4,5,6,7 and go up to n. Then when I increment it once\nand check that there is one more, so I have counted it as n times. There might be small\nerrors in n and n + 1, that is not very important. So this roughly n times we have to do this\noperation. How about this operation? Key ← A[j] I am\ngoing to do exactly n-1 times once for 2, once for3, once for 4 up to n. That is why\nthis operation is being done up to n-1 times. Just leave the comment statement. Again the\noperation will be done exactly n-1 times. We have to look at how many times I come to\nthis statement. While I >0 and A[i] > key tj -reflects the Counts the number of times\nI have to shift an element to the right, when I am inserting the jth card in to my hand.\nIn the previous example when I am inserting 7, I had to shift 2 elements 8 and 9. is going\nto count that quantity and that is the number of times I am going to reach A[i] part of\nmy while loop. While I >0 and A[i] >key I will be checking this condition for many\ntimes. For one iteration or for the jth iteration of this for loop, I am going to reach this\ncondition for tj times. The total number of times I am saying that condition is the sum\nof tj as j goes from 2 to n. ∑nj=2 tj ,while I >0 and A[i] > key,\ndo A[i+1] ← A[i] Every time I see (A[i] >key) condition I also\ncome to A[i], I am going to be see this condition, I am going to come this statement one more\ntime then, I come here because you know the last time i see the statement I would exit\nout of here. That is why this is tj -1 where j going from 2 to n.∑nj=2 (t j-1) A [i+1] ← A key. This statement here is\nnot a part of the while loop (this is an assignment operation please correct this). So this statement\nis part of the for loop is done exactly n minus one times as the other statement. So\nthe total time this procedure takes if you knew what this constant work can be computed.\nYou do not know what tj is. tj is quantity which depends upon your instance and not problem\nthere is a difference here. Problem is one of sorting. The instance is a set of numbers,\nthe sequence of numbers that have given to you. Thus tj depends upon the instance. Let us see the difference that tj makes. If\nthe input was already sorted, then tj is always 1(tj=1). I just have to compare the element\nwith the last element and if it is larger than the last element, I would not have to\ndo anything. tj is always a 1 if the input is already in increasing order. What happens when the input is in decreasing\norder? If the input is in decreasing order, then the number that I am trying to insert\nis going to be smaller than all the numbers that that i already have because the input\nis in decreasing order the number I am trying to insert is smaller than the numbers I have\nsorted in my array .What am I going to do? I am going to compare with the 1st element,2nd\nelement,3rd element, 4th element and all the way up to the element. When I am trying to\ninsert the tj element, I am going to end up in comparing with all the other j elements\nin the array. In that case when tj is equal to j, note that the quantity becomes its summation\nof j, where j goes from 2 to n. It is of the kind and the running time n square of this\nalgorithm would be some constant time plus some other constant times n minus some other\nconstant. n(C1+C2+C3+C7)+∑nj=2 t j(C4+C5+C6)-(C2+C3+C5+C6+C7) Thus the behavior of this running time is\nmore like n square. We come to this point later, when we talk about asymptotic analysis\nbut this is what I meant by f(n square). On the other hand in the best case when tj=1,\nthe sum is just n or n-1 and in that case the total time is n times some constant plus\nn-1 times some constant minus some constant which is roughly n times some constant. So\nwhat we call linear time algorithm. On an average what would you expect? In the\nbest case it is something like that you have to compare only against one element you have\nto compare only against one element and in the worst case you have to compare about j\nelements. In the average case would expect that it would take compare against half of\nthis element In an average case if you were to take it as you comparing again j/2 , even\nwhen the summation of j/2 where j goes from 2 to n, what will this be? This will be roughly\nby (n square/4) and it behaves like n square( and will come to these points in a minute).\nThis is what I mean by the best, worst and average case. I take the size of input, suppose\nif I am interested in sorting n numbers and I look at all possible instances of these\nn numbers. It may be infinitely many, again it is not\nclear about how to do that. What is worst case?\nThe worst case is defined as the maximum possible time that your algorithm would take for any\ninstance of that size. So these are all the instances are of the same size. The best case\nwould be the smallest time that your algorithm takes and the average would be the average\nof all infinite bars. That was for the input for 1size of size n, that would give the values,\nfrom that we can compute worst case, best case and the average case. If I would consider\ninputs of all sizes then I can create a plot for each inputs size and I could figure out\nthe worst case, best case and an average case. Then I would get such a monotonically increasing\nplots. It is clear that as the size of the input increases, the time taken by your algorithm\nwill increase. It is not going to happen that your input size become larger and it takes\nlesser time. Which of this is the easiest to work with?\nWorst case is the one we will use the most. For the purpose of this course this is the\nonly measure we will be working with. Why is the worst case used often? First it provides\nan upper bound and it tells you how long your algorithm is going to take in the worst case. Many algorithms occurs fairly often. Quite\noften it is the case that the worst case that for many instances the time taken by the algorithm\nis close to the worst case .So that average case essentially becomes as bad as the worst\ncase In fact for the previous example that we saw average case was like n square squared\nand worst case was also n squared there were differences in the constant but it was roughly\nthe same.The average case might be very difficult quantity to compete because as you said average\ncase if you have to compute look at all possible instances and then take some kind of average\n.Or you have to say like, when my input instance is drawn from a certain distribution and the\nexpected time my algorithm will take is typically a much harder quantity to work and to compute\nwith. The worst case is the measure of interest\nin which we will be working with. Asymptotic analysis is the kind of thing that we have\nbeen doing so far as n and n square and the goal of this is to analyze the running time\nwhile getting rid of superficial details. We would like to say that an algorithm, which\nhas the running time of some constant times squared is the same as an algorithm which\nhas a running time of some other constant times ,because this constant is typically\nsomething which would be dependent upon the hardware that your using.\n3n2 = n2 In the previous exampleC1,C2, and C3 would\ndepend upon the computer system, the hardware, the compiler and many factors. We are not\ninterested to distinguish between such algorithms. Both of these algorithms, one which has the\nrunning time of 3 n square and another with running time n square have a quadratic behavior.\nWhen the input size doubles the running time of both of the algorithm increases four fold. That is the thing which is of interest to\nus. We are interested in capturing how the running time of algorithm increases, with\nthe size of the input in the limit. This is the crucial point here and that is what the\nsymptotic analysis is all about here. In the limit how does the running time of this algorithm\nincrease in input size. That brings us to something that some of you\nmight have seen before the \"big-oh\" O-notation. If I have functions f(n) , g (n) and n represents\nthe input size. f (n) measures the time taken by that algorithm. f (n) and g (n) are non-negative\nfunctions and also non-decreasing, because as the input size increases, the running time\ntaken by the algorithm would also increase. Both of these are non-decreasing functions\nof n and we say that f (n) is O (g (n)), if there exist constants c and , such that f\n(n)≤ c times of g (n)≥ n0 . f (n) =O(g(n)\nf (n) c g(n) for n ≥ n0 What does it mean? I have drawn two functions.\nThe function in red is f (n) and g (n) is some other function. The function in green\nis some constant times of g (n). As you can see beyond the point , c (g (n)) is always\nlarger than that of f (n). This is the way it continues even beyond. Then we would say\nthat f (n) is O (g (n) or f (n) is order (g (n)). f (n) = O (g(n)) Few examples would clarify this and we will\nsee those examples. The function f (n) =2n+6 and g (n) =n. If you look at these two functions\n2n+6 is always larger than  n and you might be wondering why this 2n+6\nis a non-linear function. That is because the scale here is an exponential scale. The\nscale increases by 2 on y-axis and similarly on x-axis. The red colored line is n and the\nblue line is 2n and the above next line is 4n. As you can see beyond the dotted line\nf (n) is less than 4 times of n. Hence the constant c is 4 and would be this point of\ncrossing beyond which 4n becomes larger than 2n+6. At what point does 4n becomes larger than\n2n+6. It is three. So becomes three. Then we say that f (n) which is 2n+6 is O (n).\n2n+6 = O (n) Let us look at another example. The function\nin red is g (n) which is n and any constant time g (n) which is as same scale as in the\nprevious slide. Any constant time g (n) will be just the same straight line displaced by\nsuitable amount. The green line will be 4 times n and it depends upon the intercept,\nbut you're n2 would be like the line which is blue in color. So there is no constant\nc such that n2 < c (n). Can you find out a constant c so that n2 < c\n(n) for n more than . We cannot find it. Any constant that you choose, I can pick a\nlarger n such that this is violated and so it is not the case that n2 is O (n). How does one figure out these things? This\nis the very simple rule. Suppose this is my function 50 n log n, I just drop all constants\nand the lower order terms. Forget the constant 50 and I get n log n. This function 50 n log\nn is O (n log n). In the function 7n-3, I drop the constant and lower order terms, I\nget 7n-3 as O (n). I have some complicated function like 8n2\nlog n+ 5n2 +n in which I just drop all lower order terms. This is the fastest growing term\nbecause this has n2 as well as log n in it. I just drop n2 , n term and also I drop my\nconstant and get n2 log n. This function is O ( log n). There is a constant c such that\nthis quantity this large sum here is less than c times n square log n for n larger than\nsum n0. In the limit this quantity (8n2 log n+5n2 +n) will be less than some constant\ntimes this quantity (O (n2 log n)). You can figure out what should be the value of c and\nn0 , for that to happen. This is a common error. The function 50 n\nlog n is also O (n5). Whether it is yes or no. It is yes, because this quantity (50 n\nlog n) in fact is ≤ 50 times n5 always, for all n and that is just a constant so this\nis O(n5). But when we use the O-notation we try and provide as strong amount as possible\ninstead of saying this statement is true we will rather call this as O (n log n)). We\nwill see more of this in subsequent slides. How are we going to use the O-notation? We\nare going to express the number of primitive operations that are executed during run of\nthe program as a function of the input size. We are going to use O-notation for that. If\nI have an algorithm which takes the number of primitive operations as O (n) and some\nother algorithm for which the number of primitive operations is O (n2 ). Then clearly the first\nalgorithm is better than the second. Why because as the input size doubles then the running\ntime of the algorithm is also going to double, while the running time of O (n2 ) algorithm\nwill increase four fold. Similarly our algorithm which has the running\ntime of O (log n) is better than the one which has running time of O (n). Thus we have a\nhierarchy of functions in the order of log n, n2,n3,n4, . There is a word of caution here. You might\nhave an algorithm whose running time is 1,000,000 n, because you may be doing some other operations.\nI cannot see how you would create such an algorithm, but you might have an algorithm\nof this running time. 1,000,000n is O (n), because this is ≤ some constant time n and\nyou might have some other algorithm with the running time of 2n2 .\nHence from what I said before, you would say that 1,000,000 n algorithm is better than\n2n2 . The one with the linear running time which is O (n) running time is better than\nO (n2). It is true but in the limit and the limit is achieved very late when n is really\nlarge. For small instances this 2 might actually take less amount of time than your 1,000,000\nn. You have to be careful about the constants also. We will do some examples of asymptotic analysis.\nI have a pseudo code and I have an array of n numbers sitting in an array called x and\nI have to output an array A, in which the element A[i] is the average of the numbers\nX [0] through X[i]. One way of doing it is, I basically have a for loop in which I compute\neach element of the array A. To compute A [10],what should I do? I just have to sum\nup X [0] through X [10], which I am doing here.\nFor j ← 0 to I do A ← a + X[j]\nA[i]← a/ (i+1) To compute A [10], i is taking the value 10\nand I am running the index j from 0-10. I am summing up the value of X from X [0] - X\n[10] in this accumulator a and then I am eventually dividing the value of this accumulator with\n11, because it is from X [0] to X [10]. That gives me the number I should have in A [10].\nI am going to repeat this for 11,12,13,14 and for all the elements. It is an algorithm and let us compute the\nrunning time. This is one step. It is executed for i number of times and initially i take\na value from 0,1,2,3 and all the way up to n-1. This entire thing is done n times. This\ngives you the total running time of roughly .\na ← a+ X[j] This one step is getting executed times and\nthis is the dominant thing. How many times the steps given below are executed?\nA[i] ← a/ (j+1) a ← 0 These steps are executed for n times.\na ← a + X[j] But the step mentioned above is getting executed roughly for some constant\nn2 times. Thus the running time of the algorithm is O (n2). It is a very simple problem but\nyou can have a better solution. What is a better solution? We will have a\nvariable S in which we would keep accumulating the X[i]. Initially S=0. When I compute A[i],\nwhich I already have in S, X [0] through X [i-1] because they used that at the last step.\nThat is the problem here. a ← a +X[j] Every time we are computing X. First we are\ncomputing X [0] + X [1], then we are computing X [0] + X [1] +X [2] and goes on. It is a\nkind of repeating computations. Why should we do that? We will have a single variable\nwhich will keep track of the sum of the prefixes. S at this point (s← s+x[i]), when I am in\nthe jth run of this loop has some of X [0] through X [i-1] and then some X[i] in it.\nTo compute jth element, I just need to divide this sum by i +1.\nS ←S +X[i] A[i] ← S/ (i+1)\nI keep this accumulator(S) around with me. When I finish the jth iteration of this loop,\nI have an S, the sum X [0] through X[i]. I can reuse it for the next step. How much time does this take? In each run\nof this loop I am just doing two primitive operations that makes an order n times, because\nthis loop is executed n times. I have been using this freely linear and quadratic, but\nthe slide given below just tells you the other terms I might be using. Linear is when an algorithm has an asymptotic\nrunning time of O (n), then we call it as a linear algorithm. If it has asymptotic running\ntime of n2 , we called it as a quadratic and logarithmic if it is log n. It is polynomial\nif it is nk for some constant k. Algorithm is called exponential if it has\nrunning time of (a n), where a is some number more than 1. Till now I have introduced only\nthe big-oh notation, we also have the big-omega notation and big-theta notation. The \"big-Omega\"\nnotation provides a lower bound. The function f (n) is omega of g (n), f (n) =Ω (g(n)) If constant time g (n) is always less than\nf(n), earlier that was more than f(n) but now it is less than f(n) in the limit, beyond\na certain as the picture given below illustrates. c g (n) f (n) for n\nf (n) is more than c (g(n)) beyond the point . That case we will say that f (n) is omega\nof g (n). f (n) =Ω (g (n)) In θ notation f (n) is θ (g (n), if there\nexist constant and such that f (n) is sandwiched between C1 g (n) and C2 g (n). Beyond a certain\npoint, f (n) lies between 1 constant time g (n) and another constant time of g (n).\nThen f (n) is θ (g (n)) where f (n) grows like g (n) in the limit. Another way of thinking\nof it is, f (n) is θ (g (n)). If f (n) is O (g (n)) and it also Ω (g (n). There are\ntwo more related asymptotic notations, one is called \"Little-oh\" notation and the other\nis called \"Little-omega\" notation. They are the non-tight analogs of Big-oh and Big-omega.\nIt is best to understand this through the analogy of real numbers. When I say that f (n) is O (g (n)) and iam\nreally saying that the function f in some sense is less than or equal to g, that in\nfact what use in definition or f (n) is less than c (g (n). The analogy with the real numbers\nis when the number is less than or equal to another number. is for and is for =. θ (g\n(n) is function and f=g are real numbers. If these are real numbers, you can talk of\nequality but you cannot talk of equality for a function unless they are equal. Little-oh\ncorresponds to strictly less than g and Little-omega corresponds to strictly more. We are not going\nto use these, infact we will use Big-oh. You should be very clear with that part. The formal definition for Little-oh is that,\nfor every constant c there should exist some such that f (n) is  n0 . f\n(n) ≤ c (g(n)) for n ≥ n0 How it is different from Big- oh? In that case I said, there exist\nc and such that this is true. Here we will say for every c there should exist an n0 . This is just one slide I had put up to show\nwhat the differences between these functions is like. I have an algorithm whose running\ntimes are like 400n, 20n log n, 2 ,2n2,n4 and 2n . Also I have listed out, the largest\nproblem size that you can solve in 1 second or 1 minute or 1 hour. The largest problem\nsize that you can solve is roughly 2500. Say you using some some constant, so it lets\nsay 2500if you had this has running time let say your this is what the problem size would\nbe like 4096. Why did you say that 4096 is larger than 2500, although 20n log n is the\nworst running time than 400n, because of the constant. You can see the differences happening.\nIf it is 2n2 then the problem size is 707 and when it is the problem size is 19. See the behavior as the time increases. An\nhour is 3600seconds and there is a huge increase in the size of the problem you solve, if it\nis linear time algorithm. Still there is a large increase, when it is n log n algorithm\nand not so large increase when it is an n2 algorithm and almost no increase when it is\n2n algorithm. If you have an algorithm whose running time is something like 2n , you cannot\nsolve for problem of more than size 100. It will take millions of years to solve it. So that is the behavior that bothers us that\nis the behavior we are interested in course that is why a asymptotic analysis is what\nwe we considering most of it. So any questions till this point so with that we are going\nto stop this lecture. Today we have looked at\nasymptotic analysis and some initial notation and terminology that we be following with\nthis course."
    },
    {
        "video_id": "FWmuxvOgh6Q",
        "title": "Best Books for Learning Data Structures and Algorithms",
        "url": "https://www.youtube.com/watch?v=FWmuxvOgh6Q",
        "duration": 841,
        "transcript": "hey guys how's it going so today i want to share a few books with you that i think will help you get better at data structures and algorithms these books are not only useful if you're trying to learn data structures and algorithms for your school or your day-to-day work as a software engineer but also with technical interviews in mind so without further ado let's begin before you begin if you're new here i make videos on software engineering productivity technical interviews and that kind of stuff and if you're into similar things please subscribe and hit the notification bell icon so that you don't miss any new videos all right let's begin so the first book i recommend is this little guy called computer science distilled i came across this book probably a year ago and i think it's an amazing book just to get your head around all the topics that exist in computer science just by looking at the size of the book you'll probably guess that this is probably not an exhaustive list or a detailed explanation of the material but i think it's an amazing starting point that will at least get you familiar with the topics that exist in the space it briefly touches all the topics that you need to learn in order to be good at data structures and algorithms especially for your technical interviews it's also very light-hearted and has a good sense of humor so it's not very dense to read so even if you are just a beginner software engineer or you just started taking classes or you're switching from a different field this is a really nice and easy read to get started so this book is pretty interesting it covers your basics like ideas logic counting probability that you'll need as foundations before even starting algorithms it also has the introduction to your big on notation counting time and how things get slower or faster as your data size increases then it has the strategy section that will cover like iteration recursion backtracking dynamic programming again i can't stress enough that this is just an introduction to all these topics i mean some of these topics are huge like dynamic programming and they cover that in three pages like there's no way but the goal of this book isn't to make you an expert on any of this topic it's basically to help you sort of build the dictionary of topics in your head let's look at an example of what i mean right like there's a section here that talks about hash table it says the hash table is a data structure that allows finding items in constant time searching for an item takes constant amount of time whether you're searching among 10 million or just 10 items okay you get the rough idea you don't know in depth about what a hash table is but it looks like it is pretty efficient and it stores things and you can retrieve them in constant time by now if you've followed this book you've probably read the bigger notation so you kind of have a rough idea about what constant time means so that's cool similarly to the array the hash requires pre-allocating a big chunk of sequential memory to store data okay but unlike the array the items are not stored in ordered sequence the position of an item occupies is magically given by a hash function so this is what i mean this book introduces the topic to you but there are some of the harder topic like how the lookup is constant time or how the hash table gives you such performance is sort of magic right it's not going to explain you in depth how a hash table works but i think it gives a great introduction just one page so that you kind of get a very high level and basic understanding of what a hash table is and this is very similar with everything else it's like there's a section in graph we've seen graphs are the flexible data structure that use nodes and edges to store information they're widely used to represent data like social networks nodes are people edges are friendship relationships telephone networks nodes are telephones and stations edges are communications and much more that's it and then the next topic goes for searching in-depth searching in graph via depth research we keep following edges going deeper and deeper and then they illustrate that via a nice graph again to illustrate my point you get the idea but you're not going to get a full understanding final comment on this book is just the size itself it's so nice and light and compact easy to carry around then you can literally throw it in your backpack especially if you're a student and when you get your free time or break you just pull it out read it or if you're traveling probably not right now during covet but you know regular travel you can just carry it with you you know just refresh some topics you know it almost makes a very serious topic like data structures and algorithms kind of fun with little colorful diagrams and just the size of the book so highly recommend it especially for beginners so once you've graduated from that book you want to go ahead and get this book called rocking algorithms this book also follows a very similar pattern of being very lighthearted funny lots of diagrams to illustrate the point but goes in more depth compared to that book so once you've read that book and you've sort of have a vocabulary of words you've learned that there's thing called hash tables that exist you've learned that there's graphs and how they represent relationship between things and you can search through them via depth first or breadth first and you can do certain algorithms on them but you have no clue how to do them right like that book doesn't give you any algorithms like actual pseudo code or any code it's just an understanding and overview this is very similar but it goes into a little bit more detail and then the table of contents for this book is very similar you'll still get a bigger analysis you'll still get the sorting algorithms the basic data structures greedy algorithms searching dynamic programming that kind of stuff but because you can see it's thicker it's larger it does go into more depth it's like if that's level one this is gonna go level two i'm gonna focus on the same example for each of these books so you kind of get how in-depth they go so let's look at what this book has to say about hash tables in the other book you've learned that hash tables can give you constant time lookups and sort of how hash function makes that happen is magic right in this book however they talk about hash functions what is a hash function how does it store things and then there are a bunch of examples really nice and then it talks about like time complexity how a performance of hash table is not guaranteed right like if your hash function is bad or not efficient then you're not going to get a constant time lookup and then at this point you're like wait but the other book told me that it sort of magically happens right like it happens for built-in hash functions and stuff but now you want to understand what the magic behind it is this book's going to explain you that and then it also talks about collisions that's what happens when a hash function tries to insert two different values to the same spot that's when collision happens and then it sort of introduces that and then it also talks about when the hash function can resize and that's called maintaining a load factor see look those things you didn't know in that book but now you're gonna understand in this book right and again let me re reiterate that this is also a very light read it doesn't have any code it doesn't give you pseudo code it just gives you very illustrated examples and lots of graphs and diagrams to show you or to help you understand the idea even better than that book so i think it's a very natural progression to go from that book to this book and still till now you can go through these books without having much data structures and algorithms experience you don't need that much so even if you are like in school and you just started taking like the basic classes and you wanted to go a step ahead and kind of like get started early these are great books to get started or if you're into like mechanical engineering or different sort of engineering you want to get to coding or you you're thinking about prepping for a big fan company interview like top tech company interview and you don't know what sort of topic you need to cover these two books will sort of give you an idea and you can gauge your understanding you know these may come very naturally to some people and these books do help in that they don't talk about it in the technical jargon that most books do and it's very natural and they give real life examples so it's kind of help you grasp the topic so i think these are this is a great second book to have and then once you've figured that out maybe you've done your own research you've gone online you've looked at it in a little bit of depth and you kind of wrote some code you're you're in school and now you've taken the data structures and algorithms class that's when you bring in the big boy and this is this is a big one and it's it's almost like the bible of algorithms book it's called introduction to algorithms this as everything again those two books have same topic but in this book you will see much more technical detail it will cover everything you left pseudo code you love your mathematical analyses and everything you really need so let's look at the same thing on this guy all right in this case now we're talking about time complexities to begin with even in the first paragraph itself it starts talking about collisions but then it talks about how do you solve collisions and there's a technique called chaining it talks about that it'll give you much everything is in mathematical notation here and there are theorems and proofs and how you can get amortized constant time or you know like uh upper bound and a lower bound to your time complexity is very mathematical at this level if you're understanding algorithms and if you've gotten this far you're you're good to go you know same with graphs representations of a graph we can choose between two standard ways to represent a graph where graph is a set of vertices and edges as a collection of adjacency list as an n or an adjacency matrix either way applies to both directed and undirected graph because the adjacency list representation provides a compact way to represent sparse graph those where the edges are much lesser than the vertices and usually that's the method of choice as you can see it didn't may take any effort to explain like how oh graphs are like social networks and telephone communications that kind of stuff it's going directly to the mathematical and very uh technical uh lingo here but if you have graduated from those two books i think this is the book that you eventually want to get to because this will give you like the real implementation details and thorough understanding of algorithms but i do want to add a note here that you don't really need to know everything in this book like some of it is super mathematical you don't get carried away by this and that's also the reason that i did not recommend this book as number one because if you've never really done data structures and algorithms you're just starting and you take a look at things in this book you will you'll quit computer science i'll i'll promise you that but trust me once you once you go through the other two books and you have a good understanding of what algorithms are and what sort of things they do maybe like brush up on some math like both those book covers like some discrete math and probability counting that kind of stuff you'll find this uh much more approachable and then the final book i had for you is this is this ties very directly to technical interviews not just like learning as a software engineer it's called elements of programming interviews um this is a great book mine is an older edition i think it's like eight or ten years old so it's in c plus plus and you can get this um in java and python these days so i'll link both of those in the description below but this is a very technical interview question first approach compared to the other two books so this is a great one to either use side by side as you're learning topics or maybe go through all of them and once you feel comfortable start kind of looking into this and the chapters here are organized in a very similar approach because like like i said like the topics are same right like so you'll talk about hash table it's gonna give you a brief introduction of what a hash table is but after that it's just gonna go to a problem right like for example design a hash function for a chess game to maintain the states your function should take the state and the hash code for the state and the move and efficiently compute the hash code for the updated state so this is like a real practical implementation of hash code or a usage of ash code right away right so the other question is let s be an array of strings write a function that finds the closest pair of equal entries so not only are you learning the data structures but this will actually give you real life examples on how you can use that data structure or an algorithm to solve interview type questions i know a lot of you guys also have lead codes so maybe lead code and this is unnecessary but if you think of it lead code is like 160 a year so that's more than 10 bucks a month you know but this is going to be a like 30 40 bucks and honestly like if you can solve almost all questions on this book you don't need anything else like this not only gives you thorough explanations of how this works but it's written from engineering leaders from all of the big companies you know so i highly recommend this book so those are the three uh four books that i recommend for getting better at data structures and algorithms one final note that i wanted to add is i do suggest that you at least have an understanding of basic constructs of programming and very elementary data structures like what is an array what is a string what are primitive types what is an int what is a float how do you you know initialize variables or how do you write an if else condition how do you write a for loop while loop that's it that's that if you know that much then you'll start understanding what these are but if you if not maybe the first two books are still approachable but after that um you you'll get in trouble but um and for those um there are many free resources online that you can learn or if you're in school they're already probably teaching you but i will share a couple of other courses that are from uh really good universities and they're free on youtube so you can kind of watch those videos together with these readings and that should help you out a lot that's it if you have any questions write them in the comment below i'll try to respond to each of them if you have a question that pertains specifically to you then reach out to me on instagram and dm me and i try to respond to those too so until next time see ya bye [Music]"
    },
    {
        "video_id": "DFpWCl_49i0",
        "title": "INTRODUCTION TO DATA STRUCTURES",
        "url": "https://www.youtube.com/watch?v=DFpWCl_49i0",
        "duration": 509,
        "transcript": "[Music] hi friends so from today i am planning to upload the videos on data structures so in today's session we will see the introduction of a data structures that means what is a data structure and what are the different concepts covered in the this data structures right right so data structures what is meant by a data structure so the name itself indicates data structure so that means organizing the data in the memory is called a data structure so there are different ways to organize the data in the structure so one example we have seen in the c language that is errors so error is also a collection of elements that means a collection of memory locations so because in the memory locations we are going to store the values right so in that the structure of data is a sequential that means one after another right so it it occupies the contiguous memory locations so it is a collection of elements in that contiguous memory locations so that way the data is organized using the arrays data structure so finally the definition of data structure means organizing the data in the memory location so how many ways we can organize the data in the memory location right now let us see how many types of data structures so there are two types of data structures so what is primitive data structure and another one is non-primitive data structure primitive data structures and non-primitive data structures coming to this primitive data structures we have already seen those data structures see so these primitive data structures are our primitive data types yes so int float character double and pointer so all these comes under primitive data structure non-primitive data structure now so these these we have studied in c language this we call them as primitive data types right integer float character double and pointer it's a single memory location which can hold the value only next coming to this non-primitive it's again divided into two types that is linear data structures and non-linear data structures linear and non-linear so linear means a sequential that is nothing but a sequential so nonlinear which is not a sequential that we can call it as a random random right so this is a sequential this is random that means in this all the data will be arranged in sequential manner here the data is arranged in random manner now what are the types of linear data structure so first one is arrays lists stacks queues these four comes under linear data structure non-linear data structures only two categories are there one is a trees and graphs trees and graphs so again so this we have seen in c language arrays the sequential elements right so now we have to see about the list stack queue trees and graphs so how the data is arranged in list how the data is arranged in stack how the data is organized and used how the data is organized and traced and similarly graphs so these are the different types of data structures right so in the list there are a number of categories so under this one is single linked list double linked list circular linked list allow means lingualist right so here in trees we are going to discuss about binary trees binary search trees and there are a number of trees right so we will discuss in those sessions right so finally the data structure introduction is the same so primitive and non-primitive right and now there are common operations can be performed on these data structures operations so the major operations which can be done is searching and sorting so we can search an element in the data structure right so in the in the list we can uh sort the elements and then see we can insert the new element right insertion similarly deletion we can delete one element next updation so we can update the elements so that means we can replace one element with another element right so these are the common operations to be performed in these data structures so we can search an element in linked list we can sort the elements of a linked list we can insert an element into the linkedin list we can delete the element from the linked list and we can update the element in the linked list so these are the common operations so i will write here common operations on data structures so this is the common operations on data structures right so we are going to discuss about the list in the list we have to apply all these operations and then we have to see the stacks and we have to apply all these operations we have to cover the queues and all these operations similarly trees and graphs right so hope you you got an idea about these data structures and definitely i am going to upload the videos on all these concepts right right so let us stop here so from the next session we will start with the errors so our errors are already seen in our c sections so we will see the advantage and disadvantages of arrays right and then we will move on to the list in the list we have to see all these three so in the coming sessions we will cover all these concepts right so hope you got an idea about this introduction of data structures and if you really understood my sessions like my sessions share my sessions with your friends and don't forget to subscribe to our channel and please share my sessions with your friends and let them do subscribe to our channel"
    },
    {
        "video_id": "iZmDcfTtcNg",
        "title": "What are Data Structures?",
        "url": "https://www.youtube.com/watch?v=iZmDcfTtcNg",
        "duration": 427,
        "transcript": "what are data structures the reason we are talking about this is because if you look at the internet everyone says if you want to get into this company or that company they will ask you a question Based on data structures and algorithms so first of all why such a hype and what exactly data structures are so before we get into data structures let's talk about data see the entire software industry is based on data when you do a course on ID which we call information technology it's not about technology it's about information because we work with information so data is everything so it doesn't matter what technology you learn you basically learn or you work on it so that you can work with data example think about programming languages why do we use programming languages to process the data why do we use database to store the data why do we use AI to generate data or to understand data right I mean just to bring it down everything is data now then question arise what is data structures now if you talk about any programming language we have something called primitive data types if you want to store a number we store that in integer if you want to store a a text you store that in a string if you want to store a character you store that in a character of course depend upon different languages the term or the way you store it changes but ultimately you have some types to it where you store the data but what if you have bunch of data and if you want to store them it's not just about storing data anyone can do that it's about how do you store data efficiently and you can also save some memory the thing is if you simply dump the data you are expanding the memory and if you want to search something from the data will be difficult and that's why storing that data efficiently is very important and that's where data structures comes into picture so data structure is a way to organize and store data efficiently okay so when you say efficiently it means two things first in in terms of performance and also in terms of the memory now what about performance now think about this if you if you talk about any software application which we use it can be a normal calculator or it can be an application like Amazon website or any application which we use a banking application as well now what we do in that application is we use some features using which you can compute something you can process something example on calculator you calculate on the banking website you transfer money so what you're doing is you are basically building an application which will do some processing and the way you build an application is through algorithms now what algorithms set of instructions let's say if I want to add two numbers it's very simple you what you do is you say take two values from the user then perform the operation and give the value back to the user now those are the steps right those are the instructions now what I have mentioned the instructions those are called pseudocode because we're not actually typing a code here we're not being specific to a language let's say C C plus plus Java python JavaScript what we are simply saying is these are the steps you have to follow and that's your algorithm right but yes when you want to make it work you have to convert that into a code which was run on the computer right that's your actual software code and you can use any language as a matter right but the pseudo code will remain same now when it comes to processing of data for any task it's important for us to make it fast and also save memory now most of the companies are focusing on this concept of data structures is because they want to give a good experience to the user of course right if I'm using some application I want it to be fast now you will say okay to make the system faster you can increase the CPU speed you can increase the amount of ram you can do that but what if with the same amount of memory same amount of CPU power you can still make it more faster right and that can be done with the help of data structures now if you know how do you store that data efficiently in a proper structure and by doing that you can make your application faster because in data structures we have different type of data structures example let's say if you have bunch of data you can store that in an array but apart from Adder we have other types as well we have set we have linked list so when to use what it's not that this is best or that is best it's it's all about when to use what and to understand when to use what you have to first understand what those things are right how do you decide that this time you have to use added this time you have to use set and that's where understanding these concepts are very important now these are not the only options we have we have tree we have graph when to use them so when you understand those Concepts then we can think about okay for this situation we will use this and this is why companies are preferring candidates who knows DSA it will help them in multiple ways first it helps them to reduce the cost is because every computation see uh I know you may be thinking most of the applications which we use are free right think about Instagram now when we use Instagram of course we are not paying for it but then companies are paying for it right so the meta is paying for for you to use Instagram so because those computations will be happening somewhere maybe meta is using some cloud service let's say Amazon is in this case So Meta is basically paying to Amazon for every computation which you do okay of course they earn from ads but then they are paying for it so what they will do is they will try to optimize it they will say okay if one query takes let's say one dollar or maybe half a dollar can we just reduce it more can we just make it 10 cents so that's the thing they are trying to do and the way you can do that is by making sure you use a proper algorithm with a proper data structure so why companies are doing it to reduce the cost second to give a better customer experience so that it will run faster and if I search something it should be faster for me as well so as a customer next when companies want to hire people they have so many candidates right how will they filter those candidates now data structures algorithm becomes one of the way to filter the candidates because if you know data structures that means you have worked a lot on the particular language and you understand how how a particular system works on the other hand data structures are not the only thing you need to know if you want to be a good developer if you want to get hired there are multiple things needed example you need to have a good hold on a particular language a particular technology you should have worked on few projects understanding the entire ecosystem not just one language working with databases working with networking but then DSA becomes one of the important thing there so just to summarize what are data structures so data structures is basically a way to organize and store your data in the efficient way and there are multiple data structures options available there and you will understand that in the upcoming sessions we're going to talk about in the upcoming videos you will we will talk about what are the types of data structures we have how to use them when to use what and what algorithms available there so I hope you got some idea regarding data structures so of course entire series is important to understand that properly so I hope you're excited see you in the next video"
    },
    {
        "video_id": "ouipSd_5ivQ",
        "title": "10 Key Data Structures We Use Every Day",
        "url": "https://www.youtube.com/watch?v=ouipSd_5ivQ",
        "duration": 523,
        "transcript": "[Music] in this video we discuss a topic That's essential to every software developer data structures we use them every day and they play a critical role in building efficient systems so let's Dive Right In and take a closer look at some common examples let's start by discussing lists lists are a versatile and essential data structure in software development they are great for storing and manipulating order data they are useful in various applications like task management social media feeds and shopping carts in a task management application a list can be used to store and organized tasks for each user task can be added removed or reordered easily and user can mark them as complete as needed lists are also useful in social media applications like Twitter where they can store and display a users feed in real time ensuring the latest content is shown in the correct order arrays are another fundamental data structure they provide a fix siiz order collection of elements they're particularly well suited for situations where the size of the collection is known or doesn't change frequently arrays are commonly used in mathematical operations storing large data sets or when there's a need for random access to elements for example in a weather application an array could be used to store temperature readings for a specific location over a defined period this allows for easy calculations like averages and trans arrays are also widely used in image processing where each pixel's color data can be represented in a two-dimensional array it enables efficient manipulation and transform of the image next we have stacks Stacks follow the last in first out principle they are perfect for supporting undo and redo operations in text editors or maintaining browsing history in web browsers in a text editor a stack can be used to store each change made to the text making it simple to revert to a previous state when the user triggers an undo operation qes operate on a first in first out basis they are good for managing printer jobs sending user actions in games or handling messages in chat applications in chat applications a q can be used to store incoming messages in the order they are received it ensures that they are displayed to the recipient in the correct sequence heaps on the other hand are used for task scheduling and memory management they're especially helpful in implementing priority cues where we need to access the highest or lowest priority item efficiently trees organize data hierarchically they are useful for representing data with natural hierarchies or relationships they can be used in various applications like database indexing AI decision making or file systems in AI decision making trees like decision trees are used in machine learning for classification tasks trees are also used in database indexing where they can help speed up search insert or delete operations for example B trees and B+ trees are commonly used in relational databases to efficiently manage and index large amounts of data hash tables for efficient data lookup insertion and deletion they use a hash function to map keys to their corresponding storage locations it enables constant time access to the store values hash tables are widely used in various applications such as search engines caching systems and programming language interpreters or compilers in search engines hash tables can be used to store and quickly retrieve index data based on keywords this provides fast and relevant search results caching systems may use hash tables to store and manage cache data it allows for Rapid access to frequently requested resources and improves overall system performance another example is the implementation of symbol tables in programming language interpretors or compilers hash tables can be used to efficiently manage and look up variables functions and other symbols defined in the source code suffix trees are specialized for searching strings in documents this makes them perfect for text editors and search algorithms in a search engine a suffix tree can be used to efficiently locate all occurrences of a search term within a large Corpus of text graphs are all about tracking relationships and finding paths this makes them invaluable in social networks recommendation engines and path finding algorithms in a social network a graph can be used to represent the connections between users it enables features like friend suggestions or analyzing Network Trends R trees are good at finding nearest neighbors they are crucial for mapping apps and geolocation services in a mapping application all trees can be used to store spatial data such as points of interest this enables efficient queries to find the nearest locations based on the users's current positions now let's discuss cach friendless and how it relates to various data structures including lists arrays and other mentioned earlier in the video CPU cach is a small fast memory between the main memory and the CPU it stores recently accessed data and instructions so the CPU can access them quickly without fetching them from the slower main memory now different data structures have varying levels of cach friendliness based on how their elements are store in memory contiguous memory storage like that in arrays allow for better cach locality and fewer cach misses resulting in improved performance when an array element is accessed the Cache can prefetch and store nearby elements anticipating that they might be accessed soon on the other hand data structures with non-contiguous memory storage like link list can experience more cach misses and reduce performance in the link list elements that story in notes scatter throughout the memory and each note contains a pointer to the next note in the sequence this makes it difficult for the CPU to predict and load the next Noe before it's needed the other data structures such as trees hash tables and graphs also have varying degrees of cash friendliness based on the implementation and use case now this disparity in Access times can lead to Performance issues in modern Computing particularly in situations where cash misses occur frequently we should be mindful of this when working with performance critical application and choose the appropriate data structure based on the specific requirements and constraints of the projects and there you have it these are just some of the many data structures we use every day as software developers understanding and mastering these data structures will help us build more efficient systems making us better at our craft if you like our videos you may like our system design newsletter as well it covers topics and Trends in large scale system design trusted by 300,000 readers subscribed at blog. byby go.com"
    },
    {
        "video_id": "oz9cEqFynHU",
        "title": "Data Structures and Algorithms in 15 Minutes",
        "url": "https://www.youtube.com/watch?v=oz9cEqFynHU",
        "duration": 979,
        "transcript": "being good at data structures and algorithms is a computer science equivalent of having i mean everyone assumes you're a genius you get high paying offers from prestigious companies and you even have a high social market value on internet forums but the journey from lead cell to algo chat is not an easy one it's filled with frustration and imposter syndrome i know i've been there but now i have offers from feng which basically qualifies me to cure cancer so to give back and help even the most confusing programmers consider this video my cure since this industry is cancer [Music] the most important part of learning something new is that you actually want to learn it this is why i failed out of spanish one so before we start ask yourself why do you want to learn this don't do it to get a job at google do it because learning this changes the way you think data structures and algorithms is about solving problems efficiently a bad programmer solves the problem inefficiently and a really bad programmer doesn't even know why their solution is inefficient so let's start with that how do we rank an algorithm's efficiency [Music] say we wrote a function that goes through every number in a list and adds it to a total sum variable if you consider adding to be one operation then running this function on a list with 10 numbers costs 10 operations running it on a list with 20 numbers costs 20 operations say we wrote another function that just returns the first number in a list then no matter how large the list is this function will never cost more than one operation clearly these two algorithms have a different time complexity or relationship between growth of input size and growth of operations we communicate these time complexities using big o notation referring to input size as n common complexities are constant linear quadratic logarithmic n log n exponential and factorial our first algorithm runs in o of n meaning its operations grow in a linear relationship with the input size which in this case is the amount of numbers in the list our second algorithm is not dependent on the input size at all so it runs in constant time let's take a look at how many operations a program will have to execute in a function with an input size of 5 versus 50. it might not matter when the input is small but this gap gets very dramatic as the input size increases if n were 10 000 a function that runs in log of n would only take 14 operations while the function that runs in n factorial would set your computer on fire for big o notation we drop constants so o of 10 times n and o of n over 10 are both equivalent to o of n because the graph is still linear and bagel notation is also used for space complexity which works the same way for how much space an algorithm uses as n grows unless you sit in your room doing algorithms all day there's a good chance you forgot what logarithms are logarithms are the inverse to exponential functions let's say i wanted to find a word in a dictionary one method is to check every word one by one this is o n but nobody does that so how are humans able to find any word in a dictionary with a hundred thousand words in seconds we do something more along method two cut the search window in half each time by checking the middle element if we passed our word search on the left half otherwise search on the right half and then we repeat this until we find our word if our input n doubled in size that would only grow our operations by one in computer science this is the binary search but for the binary search to work the collection has to be sorted which opens up a huge field of computer science sorting algorithms a very basic sort is a selection sort you have one pointer at the start of the list and another pointer that is linear scan to find the next minimum element then you swap those elements and increment the pointer since you're doing a linear scan for every element in the collection this runs in all of n squared a more efficient algorithm is the merge sort a merged source splits a collection in half into sub-collections until those sub-collections can be sorted in constant time and then it works its way back up by merging sorted subcollections until the entire collection is sorted since it's splitting in half there will be log n splits and thereby log n merges it is o then to merge two sorted collections into one sorted collection since we're doing that log n times the time complexity is of n times log n no algorithm can sort an arbitrary collection in a better time complexity than that so we consider n log n to be the cost of sorting perhaps the most fundamental data structure is an array an array is an indexable contiguous chunk of memory arrays are fixed size you can't insert a ninth element into an array meant for eight elements a list data structure with a flexible size is a linked list the idea is to package your data into nodes that hold one your data and two a point that points to the next node traversing a linked list reminds me of those youtube direction chains like you see a comment that says read my profile picture and their profile picture says click on my profile which brings you to their header which says read my bio so you go to their bio and it says click the link below and you click it and then it installs a virus onto your browser if a note's next pointer points to null it's the end of the list you can add a new node to the list in constant time by just setting that pointer to the new node by doing additional tom [ __ ] with pointers we can also insert and delete nodes in constant time sometimes nodes also contain a pointer to the previous node in a variation called the doubly linked list but a major downside of linked list is that you can't access elements in constant time via index like an array in practice both programming languages have dynamically sized arrays or lists which work by creating arrays with a fixed size if the array is full capacity and you try to add a new element the programming language automatically creates a new array with double the capacity copies the current elements over and sets your pointer to that new array since this happens so infrequently we generally consider appending to a list to be a constant time operation link lists aren't the only data structure that include nodes referring to other nodes what if instead of pointing to a next node nodes pointed to a left and a right child node this is called a binary tree these child notes can also be called subtrees since trees are recursive in nature a node with no children is called a leaf node while a node with seven children is my father-in-law a common type of tree is the binary search tree which follows these rules basically a node's left child must have a smaller value while a node's right child must have a greater or equal value let's say you're looking for element x you start at the root and if the number is smaller than the root you go to the left tree if it's larger you go to the right and you keep repeating this until you arrive at your number in the worst case you have to traverse the height of the tree so the time complexity to search insert and delete elements is of h where h is the height this is efficient because on average the height will be log n but what if you inserted every element of a sorted array into an empty binary search tree well that's a linked list meaning the height would be n but we can guarantee log n time complexities using a self-balancing binary search tree such as red black trees which maintain additional properties to guarantee that the height of the tree is o of log n binary search trees are kind of considered to be a workhorse distribution that can solve most problems with decent efficiency but i found situations where binary search trees really shine are when you're asked a question about binary search trees another type of tree is a heap the primary difference between this and the binary search tree is actually use this one it's also sometimes called a priority queue because at the root of it is always the highest priority element and min heap will have the min element and the max heap will have the max element at the root but don't get me wrong the rest of the heap is unsorted it is an absolute wasteland down there searching in the rest of the heap may as well be an unsorted array we only care about what's at the top just like capitalism to insert a new element into a heap first we find the next available spot to add a leaf node then we compare it with his parents and if it's a higher priority it swaps and bubbles his way up we're doing at most log n comparisons you can build a heap from a random collection by inserting n times which cost o of n log n but there's also a way to build a heap in o of end time i'd suggest reading this wikipedia page because it's super interesting stuff and lastly since the heap is nearly complete although we can visualize it as a tree we could actually use these properties to represent it with an array one way to traverse a tree is a depth first search which is like going deep fully exploring one path and then moving on to the next one way to visit this tree in a depth first order could be to start at 10 go to 13 go to 4 then 6 then 12 then 8 and then 1 whereas another option is a breadth first search where we view it more level by level a way to print this same tree in a bfs manner could be 10 13 12 4 6 8 1. when it comes to implementation depth first search can use a stack a stack is a list-based data structure where the only two operations are add to the end and pop from the end this makes a stack lifo last in first out dfs are often done using recursion which indirectly uses a stack the recursive stack so if your recursion exceeds a certain amount of depth then you get a stack overflow let's look at a way to print this tree in a dfs matter using a stack so first initialize the stack and add the root then while there are still elements in the stack pop from the stack print that element and then add its children to the stack on the contrary a breadth first search uses a queue a queue is fifo first in first out so instead of popping from the end of the list you pop from the beginning doing the same algorithm as before but using a q instead of a stack the tree will now print in a bfs order all trees are graphs but not all graphs are trees a graph is a collection of vertices which are like points and edges which are like connections from one vertex to another vertex a graph can be directed meaning edges can only go one way so this edge means you can only go from a to b or undirected meaning you can also go from b to a two common ways to model edges are adjacency lists and adjacency matrices graphs are my favorite part of destruction algorithms so i'd like to show how cool they are with three example scenarios on where you can use them so it recently dawned on me that i know kanye west and by that i mean i know joma tech but joma tech knows jarvis johnson who knows mkbhd who knows elon musk who knows kanye west which is five degrees of separation between me and kanye west i wanted to find something shorter well turns out i know bretman rock who knows rihanna who knows kanye three degrees of separation which also means that anyone who knows me is at most four degrees of separation away from kanye if we wanted to make a program that computes the smallest degrees of separation between two people a graph would be the perfect choice you model people as vertices and you model relationships as edges the shortest path between the source node me and the target node kanye can be found with a breath first search since we're moving out level by level we can guarantee that the first time reaching the kanye node will also be the shortest path the problem with implementing this algorithm the way i just described is that nobody has a concrete list of all the people they know nor would that be publicly accessible by me but a possible variation could be in a social network like facebook where we can use the friend list as edges we would then be able to run this algorithm and find the smallest degrees of separation between any two users in that social network imagine a map system like google maps that wants to find the shortest path between two locations this is different than the last example because although they both deal with shortest paths the degrees of separations did not have weighted edges where a map system does for example if we're computing the shortest path between two vertices and there's a direct edge between them weighing 20 versus a path of two edges weighing eight each a breath first search would give us the shortest path in terms of the vertices away but not the smallest weight one algorithm that computes the shortest path in a graph with positive weighted edges is dijkstra's algorithm using the heap data structure in the original version of this video i explained dijkstra's and my video shot up 6 minutes so instead just research it for yourself if you're interested but graphs aren't just good for path finding imagine a course schedule in school with classes and prerequisites for each class and say you wanted to find the order in which you can take all your classes while still fulfilling your prerequisites well model the classes as vertices and prerequisites as edges count how many incoming edge each vertex has add vertices with zero incoming edges to a queue then pop and print the element from the queue and decrement the incoming edges of all its children if a child now has zero incoming edges add it to the cube and repeat while there are still elements in the queue this algorithm is known as a topological sort [Music] hash maps are sort of the holy grail of data structures with basically constant time retrieval of data the saying goes that if you don't know what you're doing just try throwing hashtags at the question as an example one time i was in a coding interview and froze so i just told the interviewer hmm i think the solution to use a hash map unfortunately the question was what are your biggest weaknesses so the better answer was hang up the phone to show that i have none a hashmap is a data structure built on top of an array optimized to store key value pairs what makes it so powerful is you can retrieve delete and store data in on average constant time here we have a map where keys are strings representing people's names and values are their corresponding ages we can directly access trend black's age like this it's almost as if strings can be used as indices but how is that even possible because of this little thing called a hash function a hash function will take a key and return a hash code if we take that number modulus the length of its underlying array we can use that as an index to store its value but the hash function has to compute the same hash code if given the same key so hash of trend black should always return the same hash code or else we lose the index but what if hash of trend black and hash of ziz both end with the same index well this is called collision one way to deal with this is to store our value in a linked list so when we go to stores is and see that index three already has a value we have that value point to the new value this is why a hash map is not strictly of one because if you write some god awful hash function then it won't be balanced and we will have to do a lot of linkless traversing good hash functions evenly spread out hash codes in practice modern languages use very good hash functions so you don't have to write your own an example of a hashmap is the dictionary in python or the object in javascript and remember constant lookup of data is very overpowered so try to use it when you can [Music] and that's pretty much all you need to know for data structures and algorithms a six month college course taught in 13 minutes now of course you didn't learn anything in great detail but trust me it is a lot easier to learn something in great detail if you already learned the big picture first this is why college sucks at teaching it dives very deep into one topic and then moves on to the next it's like a depth first search i believe the better way of learning is to get a general understanding and then build on it like a breath first search so if you want to keep going what are my recommendations to build on your knowledge well the first one is jomo class you know those really nice animations in this video like this one yeah i got them from joma class if you don't care about getting extremely theoretical and just want simple to the point everything you need to know and nothing you don't type lessons then jomo class makes this difficult topic very accessible but i will admit that i roasted the [ __ ] out of jomah a while back because he was pushing some actual snake oil well unlike some people he took my criticism very well and to vindicate his name he made something that is actually valuable and i will defend that he put much more effort into these explanations dropped the price from a thousand dollars to eight dollars a month and most importantly he dropped the dead weight if you're a complete beginner it also comes with a course on how to code in python and of course on sql if you're a bit more advanced but i gotta say the best part is the community aspect each lesson has a whole community behind it where people ask questions discuss topics and just learn together well i like the course so much that i actually called joma and i was like yo what the [ __ ] dude this is actually good i'm gonna start recommending this to people and he was so excited to hear that i liked it that he was actually willing to offer my audience a discount so if you go to trend.jomoclass.com then you'll get 15 off but even though paying for stuff increases the chance that you'll actually complete it you don't have to spend money not everyone has eight dollars a month to drop and i want to assure you that you can still learn everything for free so it might take a bit more self-discipline but you can do it so don't listen to anyone who says you have to pay so if you do want to go down the free route i'd recommend these college lectures they're literally taught by mit professors and posted for free online they're pretty theoretical but very comprehensive and it's perfect if you like that old-school chalkboard setting so yeah good luck guys and go get that guck 3000"
    },
    {
        "video_id": "wy0TPi9M7VM",
        "title": "Abstract Data Types | DSA",
        "url": "https://www.youtube.com/watch?v=wy0TPi9M7VM",
        "duration": 440,
        "transcript": "welcome back aliens my name is David ready and in this video we'll talk about ADT which is abstract data type now before we move towards ADT let's talk about data here of course in the previous video when we talked about what are data structures we have talked about data and we also mentioned that in the software industry everything is about data so whatever you do you are doing it for data right now with this data basically you get data from the user you process data you also give the output to the user or maybe you want to store this data in the database for the permanent storage but the thing is it's all about data and whenever we use any language doesn't matter which language you use what you do is you store that data in your code somewhere and to store that data we use something called a variable now imagine variable as a box and you are keeping your data inside that box the problem is every box need to have a type of course there are languages which are dynamically typed language where you don't don't actually mention the type of the variable but in general this box will have a type so that means if you want to store the data you need a box which is your variable and this variable also needs a type to it or this box needs a type to it now example let's say if you want to store a number so we can use something called an integer or if you have any other point values you can also use float or double now it depends about the languages how they work but in most of the languages we have something in common we have integer for the normal numbers we have a float for the point values and what if you want to store a text that's why we have string and in few languages we don't have all these types we have limited types and in other languages we have many but that doesn't matter right in general we'll be having a variable and a type to it now all this type are called data types and they are system defined data types or you can also call them as primitive types is because it's there in the language itself you can directly use them but sometimes you want to use some complex data type and we can create that with the help of some other Concepts example let's say if you want to represent a human or if you want to represent a phone now I love phone so I'm I'll be using that example so if we talk about this phone here now this phone will have a name to it right so it will have a name it will have a brand of course name is model number then brand then the configuration the amount of CPU Ram all this are your data right so if you want to represent any physical thing in the virtual world we use objects there right now in some languages which are object-oriented programming we do that with help of objects example in C we use something called structures so we can define a structure name let's say phone and inside that you can specify what are the properties there in the same way in the object limited languages we use something called class in this class you create different variables with primitive type and then the Box itself or the class itself is your complex data type or you can say user defined data type user defined because system is not giving you we are defining our own type right so that's about data and data types but let's say if you want to store a bunch of data how will you work with that and when it comes to data structure how will you store this data in a proper way see what happens is when you talk about primitive types as well every type will have a way to store data of course that's why we are getting them right so example if you are creating a variable called num now let's say this num is of type integer and then you are storing a value to it now with this variable num you can perform operations as well now what are the options you can do with integer you can add two values you can subtract two values you can divide multiply so you can perform those operations on the number but let's say you have a string there now which string of course you will not be adding two strings that doesn't make sense right why you will add two names let's say then you will get a new name okay a lot of parents are doing that for their kids but that's not the idea here right we can't add a string we cannot subtract strings but yes which string you can do something else maybe you want to see the size of a string maybe you want to concatenate two strings maybe you want to cut two strings so string has a different operations in the same way if you are creating your own type this will have data of course but also you have to you have to mention the operations which are going to perform so we have two things right we have data and we have operations now let's say in data structures you want to store a bunch of data as we mentioned and you want to store it so there's a concept of array so if you have multiple data instead of showing them in multiple variables let's say you have five numbers uh 2 6 12 21 and so on now if you have all these values you basically store that in five different variables or you can create a single array and you can store all the values there the advantage would be you have just have to use one variable name there so instead of saying a b c d e you can simply say nums you can use any variable just doesn't matter so what's important is you can use array here now when we use array we are not basically using a primitive type here we are creating our own type here own data type which is an array now in this array basically you should be also able to perform some operation example let's say what if you want to read some value you want to fetch a particular element you want to search the array maybe you want to add an element maybe you want to delete an element so this operation should be possible on that type so in the concept way when you have a type where you can perform some operation we call them as abstract is because the implementation for array changes from language to language and we don't just have added right so let's say if you want to store a bunch of values we can use list we can use set queue now when you talk about a queue here let's say now inside Q we have I mean we have one more option for that which is stack they follow different concepts so let's say if you want to add element in the queue which follows last in first out which means you have to insert from the end and you will get it from the first of course you can reverse it you can insert from the start and you can take it from the end the thing is you have you will insert from one end and you will remove from the other end so that is first in first out in stack it is reverse you do last in first out example let's say uh took an example let's say for Q we can say a queue which you follow right example if you want to buy a coffee from a cafe shop of course there's a cue there you have to stand in a queue and then when your number comes you will get the coffee so basically the first person who went there first will be getting the coffee first right in terms of Stack it is different so when you keep multiple books the first book which you can take out is the last book which you have kept there right it is the last in first out that is your stack now we have different way of implementing in different languages the concept remains same right so when you have a concept and the associated operations to it and of course with data which we call them as abstract data type we also have map but we'll talk about those things later at this point the point remember is we can create our own types and which is a concept and if you want to have data inside that and also you want to specify what operations you can perform that is your abstract data type of course in this subscription videos I will talk about how do you create them how do you work with them and it will be fun so see you in the upcoming videos Everyone bye"
    },
    {
        "video_id": "n0e27Cpc88E",
        "title": "What is Abstract Data Types(ADT) in Data Structures ? | with Example",
        "url": "https://www.youtube.com/watch?v=n0e27Cpc88E",
        "duration": 616,
        "transcript": "yo what's going on guys Thun Meyer for simple snippets and welcome back to another video tutorial under data structures and algorithms and in this video tutorial we're going to be understanding what is an abstract data type in data structures so when you're studying data structures you'll come across this term abstract data types quite often and it's a theoretical concept so we will quickly understand this and the best way to understand this is by taking examples so in this video tutorial we'll understand what exactly is an abstract or logical view and the implementation view of a data structure so that is the two ways in which we can study or view at data structures and we'll understand this by taking an example so with that being said let's get started so what exactly is a abstract data type now we have the definition of data structures which we've already seen in the previous video but I just mentioned it so that you can reiterate it so in computer science of data structure is a way of data organization management and storage that enables efficient access and modification so this is something that we've cleared out in the previous video of this data structures playlist but the way we look at data structures can be categorized into two parts you know or two different types the one is where we actually have a logical or abstract or mathematical view or model wherein we just specify what all things the data structure is going to have now we know that data structure is a way of storing data right so when I'm seeing way it means that there are some protocols there are some rules that are gonna be followed right so all those protocols all those rules can be modeled as a proper view or a model and you can basically just write down all the specifications right so that comes under the logical or abstract or mathematical model or view on the second way or the second part you can say is the implementation part wherein you use all those rules and regulations and actually implement that using some programming language right so Indian obviously we are going to be implementing these data structures in practicals by using some programming language in our case we are going to be using C++ programming right so all these programming syntaxes will be based on this mathematical and logical or abstract model so now that you have a overview of the ways in which you can look at data structures let's try to define what the abstract data type is and let's take those samples into consideration okay so when you are talking about abstract data types ADT is that is the short form are entities there are definitions of data and operations but do not have implementation details so basically the abstract data type is the logical or mathematical or abstract view that we were talking about right so here we have the entities that are definitions of data and operations but do not have implementation which means that we know what we are going to be storing and we also know the operations that can be performed and the way in which the data is going to be stored depending upon what data structure we are going through but we haven't yet implemented it in any practical sense now the reason why we do not have any implementation in edit is because every different programming language has different implementations for example a particular data structure in C can be implemented using the concept of structures but that same data structure can be implemented by using the concept of objects and classes in Java programming and so on and so forth you know so different programming languages have different implementation strategies to tackle different abstract data types so basically data structures are these abstract data types which has specifications about how the data is going to be stored and what are the operations that can be performed on these data types and these different entities but the implementation depends upon the programming language that we use okay so to get this thing more cleared out let's actually take a real-world example so here's a real world example of a smart phone okay so if we were to look at this smart phone in an abstract or logical view what we are going to be doing is we're just going to be defining what all things does a smart phone have at a high level okay for example this smart phone will have 4 GB RAM this smart phone is having a Snapdragon 2.2 gigahertz processor so every smartphone has a ram as processor has a 5.5 inch LCD screen now the screen size obviously varies depending upon what smartphone we're using but this particular smartphone has dual cameras it has Android operating system which is 8.0 version and whatnot you know and along with all these properties this smartphone also has some functionality also has some operations and behaviors right so this is what that operation stands for and this is the data rate so information can be termed as a data of that particular entity we are looking at smartphone so this is all the information and data about that smartphone and the operations are you can use your smart phone to call you can use it to perform text you can send text you can click photos you can click videos and so on and so forth so these come under the behavior and the operations rate so this is what an abstract or logical view of this smartphone looks like wherein you just hitting all the different properties and all the different operations and behaviors that that particular entity can do but when you look at the implementation view over your so when you are actually implementing this in terms of programming in terms of actual code this is how the pool would look like in a proper C++ programming language so you are creating a class so of course we have objects and classes in the C++ programming language if it was C then we could have used structures so in that we have these different variables created follow those respective properties right we have RAM size processor name we have screen size and their respective data types obviously in string float and then we also have some methods which correspond to these behaviors so we avoid call text and obviously the definition can be defined later on but right now I just want to state or show you how the implementation he would look like now if this was some other programming language let's say it was Java or Python obviously syntax is going to be changing some keywords and some mechanism is also going to be changing right which means that the implementation view can change however the abstract and logical view is independent of this implementation so this is what this hashtag datatype actually means now coming to our data structures word let's take an example in the data structures environment ok so let's take the basic integer array so we've seen an array data structure in the previous video also so let's continue with that only so that you'll understand it in a better way now here's an example which has an integer array of size 4 okay so we have the index position starting from 0 1 2 3 so array is a data structure wherein it is a collection of elements which has stored add contiguous memory locations so you can see in the orange we have memory addresses which are just one besides other so one thousand one thousand four one thousand eight and one thousand twelve so this is basically in bytes and each integer element in C++ takes up four bytes so that's why four bytes and then we have 1 0 0 4 and then one 0:08 and the addresses are allocated just right besides each other which means that it is contiguous in nature and not continuous okay we have index positions allocated and then the blue ones are the actual values so this first position is storing value 10 this 20 30 and 40 so this implementation so this is basically what an array is and all these index positions value memory address all these things are implemented in programming languages differently by different programming language right so the abstract or logical view of this integer array can be stated as this data structure or this array store a set of elements of integer datatype so in this case we are using integer array right so you can also say of a particular datatype if you want to go more generic then we need elements by position that is index so we have indexes to access different positions starting from 0 we can again modify elements by its index so if we access one particular index we can change the value at that index and we can also perform sorting and obviously there would be many more things that can be done using this array data structure right now I've just given an example of how I abstract or logical we would look like now coming to the implementation side this is how it will look like in C++ programming so the syntax would be int arr I am creating an array of size Phi in this case and not for I am having one two three four five as the actual element so I am also initializing the array I am saying C out ARR of one which means I want the value at position two okay so this is zero index position this is one index position if I am saying error of one so the output would be two over here now what I am doing is I am saying error of 2 equals to 10 so this is the third position or second index value the value is 3 over here but when I am saying error of 2 equals to 10 the new value will be 10 so I am modifying it by using the index rate so this is what is specified over here so this is basically the implementation view so when we are talking about abstract data types it is just entities which have a definition for how the data is going to be stored and what kind of data is going to be showed and what are the operations that are going to be operating on that particular data so this was an example of array rate so if you go ahead and check out other data structures as we move ahead we will obviously see them but just for example we can talk about stat szostak is a linear data structure which works on last in first out which means the last value being added into the stack will be popped out first or you can also say first in last out which means the first value that goes in will be the last one to come out so that would be written in this logical view and then obviously the implementation is something that we have to type in in form of code depending upon what kind of programming language you use so that's why implementation always keeps on changing a little bit here and there obviously the operation that is the actual behavior is always going to be the same just that since every programming language has its unique properties also the implementation slightly changes okay so this was a little bit detail about what is abstract data types you don't really have to stress out on this topic it is not really a big thing it is just as I mentioned small entities that are having definitions of data in operation but do not have implementation that's about it this is one line that should be enough and as you can see we've also talked about the example so abstract data types are nothing but the specification that we provide without the implementation okay so that's it for this video guys I hope you have got an idea about what are abstract data types you might come across this term quite often as you move I'd so thanks for watching guys if you like this video please share it with your friends do give it a like let me know comments of this video watch and I'll see you guys in the next video peace"
    },
    {
        "video_id": "bR0NYdmMg94",
        "title": "Arrays and Abstract Data Type in Data Structure (With Notes)",
        "url": "https://www.youtube.com/watch?v=bR0NYdmMg94",
        "duration": 1525,
        "transcript": "So guys I have a friend that wanted to build a PC So he approached me and asked \"Harry, can you give me a blueprint to build a PC?\" \"So that with that blueprint I can make someone build a PC?\" \"I want to do gaming and streaming.\" So I told him, \"Do this one thing, buy the motherboard of MSI tomahawk b450,\" \"And along with that, buy an AMD Ryzen 3550 processor,\" \"And with that, don't buy an expensive graphic card;\" \"Use 10-50 TI, okay?\" So I gave him this blueprint. But why am I telling this to all of you? I'm telling this to you because This blueprint of the PC that I gave him With the help of that blueprint, He can go to any store, or by himself He can build a PC. And I told him all the main components of a PC, And even if he makes a mistake, It won't be a big deal. And he won't be able to make a mistake if he follows the blueprint correctly. Okay? So what was here was, I gave him a blueprint Okay? I gave him a blueprint And a...let's say that there were some minimal requirements. That need to be put in a PC, And now, with the help of this, he'll make his PC build. Okay? Now how is PC build related to Abstract Data Type? You might not even know what PC build is, maybe Or maybe you guys are champions, but that's not the point. The point is that I told him which processor to use, I told him which graphic card to use, I told him which motherboard to use, Maybe I'll even tell him the RAM chips; \"Listen use these chips,\" You can use Kingston ones...there are a lot of chips in RAM; let it be. But, I gave him a blueprint, And I said, \"With the help of this blueprint, build a PC.\" Now this Abstract Data Type is... Abstract Data Type is a type of blueprint just like this, That does what? It tells us minimal requirements along with some operations. Okay? So there here there are some operations, And along with that, there are some minimal requirements That the data type will follow. Okay? Here I'll write minimal requirements. So abstract data type is a model To make a data structure. This means that once I give in the abstract data type, Then after seeing the abstract data type, Anyone can write the implementation of this data structure. And they can make a data structure.  And this data structure will be the actual implementation. So abstract data type if I say about arrays So you can implement it in many ways in different programming languages. But I will give you some minimal requirements And some operations on them. So this abstract data type In that, I will give you MRF. Not the MRF tyres, nor the bat one; I'll give you minimal...minimal Required functionalities, okay? And if any of this confuses you a bit, Functionality; okay? This might sound a little confusing Because you guys will ask, \"What is this ADT; how did it come?\" Just understand the way I made this for PC, I gave the minimal required functionality. In this, you can do streaming and gaming; These are some of its functionalities. And along with this, I told you That all of these things should be there. After this, anybody can make it using any cable; They can use any RAM to make it. Many implementations can be made for this. Many PCs can be made using these components. Similarly, what is abstract data type? It tells us some minimal required functionalities, It says, \"I want all of these.\" For example, if you go to a carpenter, And say, \"I want a table. I want a table that is adjustable,\" \"I should be able to code while standing, and I should be able to code while sitting.\" \"The rest is your choice to make anything,\" \"You can use iron, wood, plastic, aluminium; use anything, I'll be fine with it.\" \"But this is the minimum required functionality that I need.\" And some operations, that you can define later on your own. For example, in that table...let us say You give an operation, like...to open a drawer So you'll give an open operation in it, Along with that, you close the drawer, You'll give an operation of that type. Let's understand this with the example of an array. Now we'll talk about array ADT. Let me just clear the board If you guys are taking notes, good for you; But I have made the notes, you should definitely download them from the description.  You all should definitely download the notes. Okay? I'll rub this away now And uh...I'll rub this away And along with that, what will we do? We will study array ADT. Array as an Abstract Data Type. Okay? Arrays as an abstract data type. By the way, what are arrays? Arrays can be found in a lot of programming languages. Arrays can be found in C, C++, and Java; in Python, they are called 'lists'. But, there are some minimal required functionalities in arrays. For example, you might want to be able to so Get, There is a Get method in that And if I write Get (i), then I should get the element for the i-th position I can do any Set; I can set any number at the i-th position. As in I can make the value of index 'i' numb. Okay? Along with that, Get is done, Set is done. Then if I'm making a custom data type If I'm writing an implementation of the array, In that, I can bring in some methods, For example, here I can put in a method, 'Insert', That you can perform on arrays I can put in a method in the array, 'Add' If I want to add two arrays. So there can be many methods like these, It depends on the implementation Okay? But the minimal functionality of the array That you'll be able to Get and be able to Set. Okay? And along with that here there can be a resize functionality All of these are methods, or they are operations Okay? That you can perform on arrays So you can make your custom data type By using this blueprint And it will depend on your implementation. For example, I will show you while making it using a structure But you in C++ you can make it with classes. Now if you're making it with structure, It's your choice; it will depend on your implementation, That when the size of the array is increasing, How will you resize it? If there is a resize method Or are you copying everything? Are you using some other strategy? Are you keeping an auxiliary array already? So these things depend upon the implementation Okay? So here, in the array I have defined the Get and Set; these minimum functionalities For this abstract data type. And along with that, these methods can be various methods There can be various operations that you can find in an array. Okay? Now all these operations can be defined And we can make our own array ADT. Now, what does abstract mean? Abstraction means hiding details. It's very important. What does abstraction mean? In the local language, if I have to explain abstraction, Then it means, eat the mangoes, don't count the kernels. What does abstraction mean? Abstraction means eat the mangoes, don't count the kernels. Meaning, don't go for the implementation details. Don't go for the implementation details. Only go for the usage Please use it. Implementation is hidden. All these things will be hidden We'll say that use Insert and insert it in the array It has nothing to do with you, That we've made a structure inside the insert Or we've made a pointer Or if we've cramped up anything else inside it That's my concern; you guys just use it. Like when you buy a phone, Do you open it and see it? Which screws does it have, and which processor does it have? You read the box, that it has a certain processor But it's not as if you guys open the screws Because the mobile phone manufacturers tell you To talk, use Instagram, use Whatsapp, use Facebook Watch Youtube, watch CodeWithHarry videos Do whatever you want. But all those details are abstracted from you. Now the Youtube app How do you know what code it has? It's abstracted from you, it's hidden. So hiding the details. Abstraction means hiding the details. About what has happened and how. Hiding this is called abstraction. Okay? So this is an abstraction. And abstract data type...I dropped my pen. No worries. So this is an abstract data type. Okay? So we have studied arrays ADTs. Now let's discuss an array; what actually is an array? I'll rub away these methods and all I'll clear the board up. And I'll tell you a bit about what an array actually is. Okay? So an array is a collection of elements. Collection of elements. Accessible by an index. I've given this in the notes; so don't worry too much. Accessible by an index. By an index. I'll write a little fast. Scribbled handwriting. But I've written the notes in perfect handwriting. Don't think that the notes are like this; the notes aren't like this. This is only to make you understand that I'm writing fast. So what is an array? Let's see here. Now I told you that the memory layout of the C programme Here there is a code section. Okay? Then what do we have here? We have the initialise and the uninitialise segments. I won't talk about those. Then we have the stack. Okay? Here we have the heap. Okay? Inside the stack, there are local variations of a function. Okay? So you called for a function; then it will have its own stack. In that, if you make an array then it will be here. And you'll get the memory here, in the stack. But the heap, i.e in the dynamic memory... If we use the memory as a resource in the heap of the array, Assume you say that you want an array of 10 elements, Now here 0...1...2...3. Till will go till 9. And the index of the array In most programming languages, starts at 0 It has a reason; when we start from 0, We get a certain advantage but I won't go there. But, you can search on the internet There's a paper by jee-stars You can see; in that they've explained what will happen if it starts from 1 If it starts from 0; how calculations will become easy When we try to access the index ahead. I won't go there. I want to tell you guys, What an array is. Now assume that here...or here You request an array in the heap or in the stack So you get contiguous blocks of memory. Means, that if its address is 50\nOr if its address is 10, And I'm assuming an integer, It's an integer of 4 bytes. Okay? There is also a 2-byte integer too But I'm assuming a 4-byte one. It depends on the architecture. 14...18...22...26...this is how the address is. This means, that 4 bytes is one integer. Okay? Here assume this is 6. Here in 4 bytes, there will be one integer. Here in 4 bytes, there will be one integer. And there will be an integer every 4 bytes. Now assume that this is 26...so this will become 30. And along with that, this will be 34. And from here, the other memory's location will start. Which I don't have; it's not under my control And that is 38; okay, and from here the other memory will start. Remember one thing, you cannot resize an array. Because if you resize it, then...you want this memory This memory. Now assume you made this array, Okay? You made this array The compiler will say, \"Okay,\" \"From 10 till 38; this block of memory is yours.\" Okay? And you will get it. Now assume that after some time you go to a shopkeeper, \"Uncle please give me this toffee,\" He says, \"Take it,\" Then you go and you think that this isn't a good toffee. Then you say, \"Uncle please take it back,\" Then he asks, \"What's going on? I'm not here to take it back,\" He gets angry. Okay? So what happens here? Goods once sold can't be returned. Okay? So here, if you say that you don't want 38, you want a greater one Then you won't get it. Why won't you get it? See, when you requested a memory till 38, Then it is possible that some other application was given some memory by the compiler. Okay? It will be doing its job with this memory. Otherwise in the same programme It must have allocated a variable in correspondence with this memory. So now you're saying that you want to increase it So you cannot make it larger in this array. You cannot make it larger in this array. You can increase it in the linked list, we'll talk about that ahead, But you cannot make it larger. Because you've asked for memory till 38, After that who knows who's using the memory ahead of that; It won't be used in every case. The compiler can't even guarantee to increase it That, \"I will guarantee that I'll increase it whenever you want or resize it,\" So for resizing it, what you'll have to Assume the content of this array...1...2...8...12 And assume this is 8...36...42 So you'll have to copy all of this content into a new array. If you want to request a larger array. You'll have to copy all of this content one by one. You can resize it this way. Okay? You can resize it this way. Now if you're making the array in a heap, You can make it in C++ If you are then, you can use the new operator If you're making it in C, then you can make it like this: int*malloc. By the way, if you haven't seen my video about C It's a 15-hour video with notes. Do watch that. Because all these things are needed here. I've told these things very slowly with practice If you skip the practice set, it'll be over in 6 hours. Okay? Do watch that video. I've made you practise a lot in that video. That's why it's taken a lot of time...it's of 15 hours. Malloc, and... assume here I'm doing 10xsize of int. I'll write it like this. 10 multiplied by, i.e star, size of, i.e size of the operator, And inside that int, i.e whatever is the size of int. So assume this is an 'a' pointer, okay? This is an int*a. I have an int*a. And I've pointed it with this. Assume I made an array of size 10, So I'll get 0-9 as my indexes. Indices. Okay? And after that, I want to expand this array. And now I want it from 0-19, That means that I want to store 20 elements in my array, okay? So what will happen? To store 20 elements in the array, What will I do? I'll make another pointer. Int*b=int*malloc(20*size of int) I'll do it like this. And then I'll write, a=b. Okay? I'll point this pointer in this. I can resize it in this way. Directly I cannot resize it, I can't increase it It won't get this block; no. It can be resized this way An array cannot be resized Now, why should we use an array? Why did we make an array? Let's see here. We made the array because Because at one point I have these 10 addresses Then you'll say, \"Tell me what the 4th element will be,\" So here I will count and I will know that this is at a distance of 4 So the fourth element; I'll try to find in one calculation i.e in O(1) time. Listen to me carefully. I will use 10 And after that, I'll write + 4x(i) This will be its address Of the i-th integer. Let's see if I've written it correctly. If I do i=0 here, then I'll get 10. If I do i=1 here, then I'll get 14. I'll write here 0...1...2...3...4...5...6. Now assume that I want to know where the 5th element is. I want the address of the fifth element; As in I need 30. What I'll do is; I'll put 5 here 5x4=20; 20+10=30. So I'll directly get the address and I'll be able to access it. So there is faster access in an array. It's not like if I want to access this then I'll have to come from all the way here adding the pointer. So this traversal; if I'd made it with a variable or linked list or in any other way, I would have needed it on O(1). Now my work is done in O(1). Oops. My work is done in O(1); in constant time. I can access the elements of the array in O(1) time; in contact time. Okay? So this is benefitting me a lot; I can access anything faster This Get method runs very fast. This Set method also runs very fast. Because I can reach wherever I want to go. I'll directly say that whatever value is at that place, To dereference it and numb its value. Okay? This way I can change the values very quickly. But here there's a scam. What's the scam? I'll tell you. The scam is that if I want to insert an element here, If here I want to insert 5 after 8; So if there isn't large enough, I'll have to make another one. I'll have to copy these elements here, After that, I'll have to keep the new element that I'm inserting. Then I'll have to copy 36 and 42 here. Okay? Then I'll have to copy 36 and 42 here. I'll have to make a new array. But this insertion is becoming costly for me Along with that, if I want to delete something Assume that I don't want 8 here So this deletion will also be costly for me What will I have to do? I'll have to move these elements a bit. It is possible that I'm deleting the first element And the elements left to move inside the array, Those are 'n'. It will take O(n) time to only move them. Okay? And after that, one place will be wasted. Let's not worry too much about that wastage. But after that you can imagine; I'm moving all the elements ahead of it. That operation there will be costly for me. We'll do this one thing now, We'll write Get and Set directly. The programming language gives them to you by default If you've made the array in C language, You can write it like Arr(i) and implement it in Get. And in Set also you can do it the same; write Arr=(numb). So Get and Set is very easy in the C language. But we'll see a few other operations, We'll implement this array ADT with the help of structure. Because it's our choice, how we build our PC. This is our abstract data type. We'll build it however we want to. And we'll add many more operations So that whenever a user is using the array, then they can do so very easily. And they should not have any problems while using array ADT. For example, if he/she goes to 'Add Array' to add two arrays, Now in C language, you'll have to write whatever function or programme that you have to add. But in my ADT I will provide the user with the ability to use my Add method. So that he/she will be able to add lots of arrays directly. Okay? So we implement this thing with the help of structure. I hope ADT is understood. And that array is understood. That why we use arrays. Faster retrieval, faster updation. Where does the scam happen in the array? At the time of deletion and insertion. If I want to insert an element, it becomes costly. Because I'll have to move it; All of this is contiguous memory, right? All these locations are contiguous. And if you say, \"Send 8 at the end; bring this here,\" So it doesn't work like that. I have to maintain the order, And do the insertion after that. There I will face a problem. And if I need more space, Then for that, I'll have to make another array. I'll have to copy everything in that. So that's why we use an array; because there are certain advantages to that. There are some disadvantages too, but it varies from use case to use case. When I use it; when I don't. It depends from problem to problem. And you'll get that by practising. And I will ensure that you get it. Now here I'd like to say something, These notes for array, I'll give them to you. I've written ADT and array pretty well. Now I'll show you the notes, And along with that, If you haven't accessed my data structures playlist, Then please do so. And also, I'm posting a lot of content on Instagram these days, If you haven't followed me on Instagram, then do so. Anytime in the future, if there's an update, About the course; if I give any supplementary material or additional problems. So if something happens, I update it on Instagram quickly. So you can check it out. The link is in the description. Now let's check out the notes about ADTs and Arrays. And after that, we'll practise a bit. We'll write some methods; and understand this topic in depth. So guys this is the PDF that I've written for you guys. And with these handwritten PDFs, you'll at least come to know what an abstract data type is What an array is; so here I've defined it well, All you need to remember is In an abstract data type, abstraction means hiding the implementation details. And you are being given an assurance; a provision To carry out these operations. Now there is some minimal functionality, Like Get, Set; I want all of these things in this. But here along with some minimal functionality, There are a set of operations that will be there in this abstract data type. Now I have defined array as an ADT. Its implementation can be done in various programming languages. Array ADT holds a collection of elements It can float, it can be int, it can be classes in C++, and it can be structure in C language. This means that there should be similar elements. The items should be similar. It can't be that one is int and the other is float. I've told this to you in the array. If you guys don't know the array in C language, Then I'll show you which video to watch. I've made a 15-hour video of the C language, You have to watch it. Everything will be clear in that. Learn C with 15 hours and notes; I've told everything in here. I'll just say one thing; the reason why it's 15 hours long Because in it I've made you do a lot of practice programmes and projects. That took a lot of time. But if you look at the concepts, I've done the time stamping, guys Down below in the description, If I open this video, you'll find the time stamp So according to that, you can open the chapters and you can skip the practice set. Then even if you have less time, you'll be set. Okay? So here, we saw all these things on the board; I'd like to tell you one more thing, about static and dynamic arrays. Static arrays are those whose size cannot be changed. But dynamic arrays are those whose size can be changed. Now you'll say, \"We just talked about how the size of an array can't be changed in C language.\" But we can make an ADT, i.e an abstract data type That will implement this functionality. The functionality of dynamic arrays. How will it be in the C language? You can copy the previous elements into the new elements. So we can make an abstract data type of a dynamic array. And that will implement this feature. Okay? So here I have given a quick quiz, To code all the operations for the ADT that I've made Max, Min, Search, Insert and Append. To implement all of these. We'll do this in a while; I've told you about memory representation sufficiently. That the array can be accessed and updated in O(1) time. Because only one calculation has to be done And it will take constant time, regardless of if you're updating the element Or if you want to access it from there. It depends on you and what you want to do. I've written here index 0..1...2...3 It's a contiguous memory location, so from here it will have 10 memory address From here it will have from 10-14 From here it will have from 14-18 From here it will have from 18-22 From here it will have from 22-26. It's 4 bytes each; in every bite, there are 8 bits. In every bit, 0 or 1 is stored. So the computer only speaks in the language of 0 or 1. Here I won't go into too much detail; If you want to know those types of details, I've made a practice playlist of the C language. Here too, videos are going to be added. So you can watch this; if you really want to know all these things, Binary to decimal; decimal to binary, bit operations and Different types of practice programmes for the C language. I've made a separate playlist for that. So you can watch this; I'll be adding a lot of videos here. But if you want to stick to data structures All I'll say is keep following this course And you will definitely like it and it will benefit you a lot. So that is it for this video guys. I hope you have accessed this playlist of data structures. If you haven't then please do and bookmark this playlist. And I want to request you that please; I'm working very hard for this course specifically So if it's possible, please share the videos. I don't think it takes a lot of time to share Simply take the link and forward it to your WhatsApp groups of school, college, or wherever you work. If you do this then it will help me a lot, and I'll bring more of these courses for free with notes. And there are many more things that I'm planning, And if you want to make things easier for me, Please share it as much as you can. Thank you so much guys for watching this video, And I will see you next time."
    }
]